<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Tseng, Ching-Wei | My Page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a  class="logo"> "We don't quit, we don't cower, we don't run. We endure and conquer." </a>
									<ul class="icons">
										<li><a href="https://twitter.com/adamstseng" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="https://github.com/adamstseng" class="icon fa-github"><span class="label">Github</span></a></li>
										<li><a href="https://www.linkedin.com/in/chingweitseng/" class="icon fa-linkedin-square"><span class="label">Linkedin</span></a></li>
										<li class="icon fa-envelope">  (sky1001993@gmail.com)</li>
									</ul>
								</header>
							
							<!-- Banner -->
							<section id="banner">
								<div class="content">
									<header>
										<h2>About Me</h2>
									</header>
									<p> My name is <strong>Tseng, Ching-Wei</strong> (Adams Tseng). I am an algorithm researcher that interested in computer vision/image processing/deep learning. My main research fields include low-vision problems like depth image enhancement, super-resolution, denoising, and inpainting. </p>

									<h4>Experience</h4>
									<ul>
										<li>Algorithm Engineer (RDSS) in Mediatek <i>(2017 - Present)</i></li>
										<li>Research Assistant in Computer Vision Lab, NTHU <i>(2015 - 2017)</i></li>
										<li>Research Assistant in Vision and Learning Lab, NTHU <i>(2013 - 2015)</i></li>
										<li>Summer Intern of Sensor Department in TXC Corporation <i>(2013)</i></li>
									</ul>

									<h4>Education</h4>
									<ul>
										<li>M.S. in Computer Science, NTHU, Taiwan <i>(2015 - 2017)</i></li>
										<li>B.S. in Industrial Engineering and Engineering Management NTHU, Taiwan <i>(2011 - 2015)</i></li>
									</ul>

								</div>
								<span class="image object">
									<img src="images/myself.JPG" alt="" />
								</span>
							</section>

							<!-- Content -->
								<section>


									<h2>Publications</h2>
									<div class="row">
											<div class="4u 12u$(small)">
												<span class="image main"><a href="https://github.com/adamstseng/general-deep-image-completion"><img src="images/bmvc17_preview.jpg" alt="" /></a></span>
											</div>
											<div class="8u$ 12u$(small)">
												<h3>General Deep Image Completion with Lightweight Conditional Generative Adversarial Network (BMVC 2017)</h3>
												<strong>Ching-Wei Tseng</strong>, Hung-Jin Lin, Shang-Hong Lai
												<p>Recent image completion researches using deep neural networks approaches have shown remarkable progress by using generative adversarial networks (GANs). However, these approaches still have the problems of large model sizes and lack of generality for various types of corruptions. In addition, the conditional GANs often suffer from the mode collapse and unstable training problems. In this paper, we overcome these shortcomings in the previous models by proposing a lightweight model of conditional GANs with integrating a stable way in adversarial training. Moreover, we present a new training strategy to trigger the model to learn how to complete different types of corruptions or missing regions in images. Experimental results demonstrate qualitatively and quantitatively that the proposed model provides significant improvement over a number of representative image completion methods on public datasets. In addition, we show that our model requires much less model parameters to achieve superior results for different types of unseen corruption masks.</p>
											</div>
											
											<div class="4u 12u$(small)">
												<span class="image main"><a href="http://ieeexplore.ieee.org/document/7820834/"><img src="images/apsipa16_preview.jpg" alt="" /></a></span>
											</div>
											<div class="8u$ 12u$(small)">
												<h3>Depth Super-Resolution via Multi-Frames Registration and Deep Learning (APSIPA 2016)</h3>
												<strong>Ching-Wei Tseng</strong>, Hong-Ren Su, Shang-Hong Lai, JenChi Liu
												<p>In this paper, we develop an algorithm for depth image super-resolution from RGB-D images, which are acquired under different imaging conditions so that we can combine them to improve the image quality with precise 3D registration. We focus on how to increase the resolution and quality of depth images by combining multiple RGB-D images and using the deep learning technique. In the proposed solution, we combine multiple RGB-D images by 3D alignment from 3D feature point correspondences and apply the guided filter as the input to SRCNN to obtain the up-sampled depth images. We show depth quality improvement of the up-sampled depth maps by using the proposed algorithm over the traditional methods through experimental results on some public-domain RGB-D datasets.</p>
											</div>

											<div class="4u 12u$(small)">
												<span class="image main"><a href="http://www.bmva.org/bmvc/2016/papers/paper123/index.html"><img src="images/bmvc16_preview.jpg" alt="" /></a></span>
											</div>
											<div class="8u$ 12u$(small)">
												<h3>Accurate and Robust Face Recognition from RGB-D Images with A Deep Learning Approach (BMVC 2016)</h3>
												Yuancheng Lee, Jiancong Chen, <strong>Ching Wei Tseng</strong>, Shang-Hong Lai
												<p>Face recognition from RGB-D images utilizes 2 complementary types of image data, i.e. colour and depth images, to achieve more accurate recognition. In this paper, we propose a face recognition system based on deep learning, which can be used to verify and identify a subject from the colour and depth face images captured with a consumer-level RGB-D camera. To recognize faces with colour and depth information, our system contains 3 parts: depth image recovery, deep learning for feature extraction, and joint classification. To alleviate the problem of the limited size of available RGB-D data for deep learning, our deep network is firstly trained with colour and grayscale images from CASIA-WebFace dataset, and later fine-tuned on depth images for transfer learning. Our experiments on some public and our own RGB-D face datasets show that the proposed face recognition system provides very accurate face recognition results and it is robust against variations in head rotation and environmental illumination.</p>
											</div>
									</div>

									<hr class="major" />

									<h2>Honor</h2>
									<h4>A Mental Workload Assessment System based on Human Action Recognition with RGB-D Camera</h4>
									<ul>
										<li> <strong>Research Creativity Award</strong> 2015 College Student Research Project of Ministry of Science and Technology </li>
										<li> <strong>Excellent Award</strong> 2015 National IEM Thesis and Technical Report Competition for Undergraduates </li>
										<li> <strong>2nd Place</strong> 2015 Thesis Awards of Student Branches of Chinese Institute of Engineer </li>
										<li> <strong>2nd Place</strong> 2014 NTHU IEEM Thesis Demonstration Award </li>
									</ul>

									<h4>"SuPrice" -  Smart Cloud and Electronic-Price Tag System</h4>
									<ul>
										<li> <strong>1st Place</strong> 2014  19th International ICT Innovative Service Awards: Subject of Acer BYOC Application </li>
									</ul>

									<h4>Having Fun with Seeing Houses: Smart Motion Sensing and Virtual Reality</h4>
									<ul>
										<li> <strong>2nd Place</strong> 2013 Ministry of Economic Affairs: Smart and Innovative Domestic Proposal Activity Awards </li>
									</ul>

								</section>

						</div>
					</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>